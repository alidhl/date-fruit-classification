{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Date Fruit Classification**\n",
    "In this project, we aim to classify different types of date fruits using machine learning techniques. The dataset consists of images of 9 different classes of dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "\n",
    "print(f'There are {len(os.listdir(train_dir))} classes in the training set')\n",
    "num_of_images = 0\n",
    "for class_name in os.listdir(train_dir):\n",
    "    print(f'There are {len(os.listdir(os.path.join(train_dir, class_name)))} images in {class_name} class')\n",
    "    num_of_images += len(os.listdir(os.path.join(train_dir, class_name)))\n",
    "\n",
    "print(f'There are {num_of_images} images in total in training set')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(os.listdir(test_dir))} classes in the test set')\n",
    "num_of_images = 0\n",
    "for class_name in os.listdir(test_dir):\n",
    "    print(f'There are {len(os.listdir(os.path.join(test_dir, class_name)))} images in {class_name} class')\n",
    "    num_of_images += len(os.listdir(os.path.join(test_dir, class_name)))\n",
    "print(f'There are {num_of_images} images in total in test set') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Samples of The Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(\"Sample of images in training set\")\n",
    "print(\"Sample of Ajwa Dates\")\n",
    "ajwa_images = os.listdir(os.path.join(train_dir, 'Ajwa'))\n",
    "plt.imshow(load_img(os.path.join(train_dir, 'Ajwa', ajwa_images[0])))\n",
    "plt.show()\n",
    "print(\"Sample of Galaxy Dates\")\n",
    "galaxy_images = os.listdir(os.path.join(train_dir, 'Galaxy'))\n",
    "plt.imshow(load_img(os.path.join(train_dir, 'Galaxy', galaxy_images[0])))\n",
    "plt.show()\n",
    "print(\"Sample of Sokari Dates\")\n",
    "sokari_images = os.listdir(os.path.join(train_dir, 'Sokari'))\n",
    "plt.imshow(load_img(os.path.join(train_dir, 'Sokari', sokari_images[0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Image Resolution Check**\n",
    "\n",
    "In the upcoming steps, we'll be **reducing the resolution** of our images. This strategy helps us **decrease the number of trainable parameters**, thereby making our model more efficient. Importantly, we aim to achieve this **without compromising the accuracy** of our classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img = load_img(os.path.join(train_dir, 'Ajwa', ajwa_images[0]))\n",
    "img_array = img_to_array(sample_img)\n",
    "print(f'Shape of image array: {img_array.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training and Validation Generators**\n",
    "Will be using **ImageDataGenerators** to augment the data on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_generators(TRAINING_DIR):\n",
    "  train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                     validation_split=0.1,# Reserve 10% of the data for validation\n",
    "                                     horizontal_flip=True,)\n",
    "\n",
    "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
    "                                                      subset = 'training',\n",
    "                                                      batch_size=32,\n",
    "                                                      class_mode='categorical',\n",
    "                                                      target_size=(200, 200))\n",
    "\n",
    "  validation_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
    "                                                                subset = 'validation',\n",
    "                                                                batch_size=32,\n",
    "                                                                class_mode='categorical',\n",
    "                                                                target_size=(200, 200))\n",
    "  return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator = train_val_generators(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training the Model**\n",
    "\n",
    "With our dataset prepared and ready, we can now shift our focus towards constructing and training our machine learning model. This step involves defining the architecture of the model, compiling it, and then training it on our data. Will be using **transfer learning** to improve the model accuracy by taking weight from **MobileNet** which is a compact and effienct pre trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "# Load the MobileNet model\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(9, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('val_accuracy')>0.95):\n",
    "      print(\"\\nReached 95% validation accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model with the optimal learning rate\n",
    "Chose the following **learning rate** after many trial and errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit(train_generator, epochs=50, validation_data=validation_generator, callbacks=callbacks, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualizing the Results**\n",
    "\n",
    "In this section, we'll take a closer look at the outcomes of our model training. By visualizing these results, we can gain deeper insights into the performance of our model and identify potential areas for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "# Training and validation accuracy\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "# Training and validation loss\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                  target_size=(200, 200),\n",
    "                                                  batch_size=1,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=False)\n",
    "y_pred = model.predict(test_generator, steps=len(test_generator), verbose=1)\n",
    "# Convert prediction probabilities to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = test_generator.classes\n",
    "# Get class labels\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=class_labels))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matrix, annot=True, cbar=False, cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Saving The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.model.save('model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
